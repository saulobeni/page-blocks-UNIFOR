# ğŸ“Š Page Blocks Classification â€” UNIFOR

Projeto individual desenvolvido na disciplina **InteligÃªncia Artificial Computacional**  
Centro de CiÃªncias TecnolÃ³gicas â€” Universidade de Fortaleza (UNIFOR)

Este repositÃ³rio contÃ©m a implementaÃ§Ã£o manual de diversos classificadores de Machine Learning para realizar a classificaÃ§Ã£o de blocos de pÃ¡ginas de documentos digitalizados, utilizando o dataset **Page Blocks** disponÃ­vel no OpenML.

---

## ğŸ¯ Objetivo do Projeto

O objetivo deste projeto Ã© avaliar e comparar o desempenho de diferentes algoritmos de aprendizado supervisionado no problema de **classificaÃ§Ã£o de layout de documentos**, identificando blocos como:

- Texto
- Linha horizontal
- Imagem
- Linha vertical
- GrÃ¡fico

Os algoritmos sÃ£o avaliados usando:
- ValidaÃ§Ã£o Cruzada Estratificada
- AcurÃ¡cia
- PrecisÃ£o
- F1-Score
- Tempo de execuÃ§Ã£o (treino e teste)

---

## ğŸ—‚ï¸ Dataset Utilizado

**Nome:** Page Blocks  
**Fonte:** OpenML (ID: 30)  
**InstÃ¢ncias:** 5.473  
**Atributos:** 10 atributos numÃ©ricos  
**Classes:** 5 (classificaÃ§Ã£o nominal)

Cada instÃ¢ncia representa um bloco de uma pÃ¡gina extraÃ­do de documentos reais.  
As variÃ¡veis descrevem caracterÃ­sticas como altura, largura, Ã¡rea, quantidade de pixels pretos, transiÃ§Ãµes branco-preto, entre outras.

---

## ğŸ§  Algoritmos Implementados

Neste projeto, **nenhuma biblioteca pronta de Machine Learning foi utilizada** (como scikit-learn).  
Todos os algoritmos foram implementados manualmente em Python.

### ğŸš€ Classificadores avaliados:

- **KNN (k-Nearest Neighbors)**
  - DistÃ¢ncia Euclidiana
  - DistÃ¢ncia Manhattan

- **Perceptron Multiclasse**

- **MLP (Multi-Layer Perceptron)**  
  Rede neural com:
  - Camada de entrada
  - Camada oculta
  - Camada de saÃ­da

- **Naive Bayes**
  - Univariado (variÃ¢ncia independente)
  - Multivariado (covariÃ¢ncia entre atributos)

---

## ğŸ§ª Processo Experimental

O fluxo de execuÃ§Ã£o segue:

1. Leitura do arquivo `.arff`
2. CodificaÃ§Ã£o das classes
3. NormalizaÃ§Ã£o dos dados (Z-score)
4. DivisÃ£o por validaÃ§Ã£o cruzada estratificada
5. Treinamento dos modelos
6. Teste em cada fold
7. CÃ¡lculo das mÃ©tricas
8. GeraÃ§Ã£o da tabela final com mÃ©dia e desvio padrÃ£o
9. ExportaÃ§Ã£o dos resultados para arquivo Excel

---

## ğŸ“ Estrutura do Projeto

```bash
page-blocks-UNIFOR/
â”‚
â”œâ”€â”€ main.py                 # Arquivo principal de execuÃ§Ã£o
â”œâ”€â”€ reader.py               # Leitura do dataset ARFF
â”œâ”€â”€ utils.py                # NormalizaÃ§Ã£o e codificaÃ§Ã£o
â”œâ”€â”€ metrics.py              # ImplementaÃ§Ã£o das mÃ©tricas
â”œâ”€â”€ cross_validation.py     # ValidaÃ§Ã£o cruzada estratificada
â”‚
â”œâ”€â”€ knn.py                  # ImplementaÃ§Ã£o do KNN
â”œâ”€â”€ perceptron.py           # ImplementaÃ§Ã£o do Perceptron
â”œâ”€â”€ mlp.py                  # ImplementaÃ§Ã£o da rede neural MLP
â”œâ”€â”€ naive_bayes.py          # ImplementaÃ§Ã£o do Naive Bayes
â”‚
â”œâ”€â”€ dataset_30.arff         # Dataset Page Blocks
â”œâ”€â”€ resultados_pageblocks.xlsx  # Tabela de resultados gerada
â””â”€â”€ README.md               # DocumentaÃ§Ã£o do projeto
````

---

## â–¶ï¸ Como executar o projeto

### ğŸ”¹ 1. Requisitos

VocÃª precisa de Python instalado (recomendado: Python 3.8+)

---

### ğŸ”¹ 2. Executar anÃ¡lise completa

No terminal, dentro da pasta do projeto:

```bash
python main.py --data dataset_30.arff
```

---

### ğŸ”¹ 3. ParÃ¢metros opcionais

VocÃª pode personalizar os parÃ¢metros assim:

```bash
python main.py --data dataset_30.arff --folds 5 --k 5 --hidden 32 --epochs_perceptron 50 --epochs_mlp 100
```

**Significado:**

| ParÃ¢metro             | DescriÃ§Ã£o                         |
| --------------------- | --------------------------------- |
| `--folds`             | NÂº de folds da validaÃ§Ã£o cruzada  |
| `--k`                 | Valor de K no KNN                 |
| `--hidden`            | NeurÃ´nios na camada oculta da MLP |
| `--epochs_perceptron` | Ã‰pocas de treino do Perceptron    |
| `--epochs_mlp`        | Ã‰pocas da MLP                     |

---

## ğŸ“ˆ Resultados

Os resultados sÃ£o apresentados em uma planilha Excel:

```
resultados_pageblocks.xlsx
```

Contendo:

* MÃ©dia e desvio padrÃ£o da AcurÃ¡cia
* MÃ©dia e desvio padrÃ£o da PrecisÃ£o
* MÃ©dia e desvio padrÃ£o do F1-Score
* Tempo mÃ©dio de treino
* Tempo mÃ©dio de teste

---

## ğŸ† ConclusÃ£o

O classificador **KNN com distÃ¢ncia Manhattan** apresentou o melhor equilÃ­brio entre:

* Desempenho
* Estabilidade
* EficiÃªncia computacional

Enquanto isso, redes neurais simples (MLP), apesar de mais complexas, nÃ£o apresentaram bom desempenho nesse dataset especÃ­fico.

---

## ğŸ“š ReferÃªncia do Dataset

Malerba, D., Esposito, F., & Semeraro, G. (1994).
Multistrategy Learning for Document Recognition. *Applied Artificial Intelligence.*

---

## ğŸ‘¨â€ğŸ“ Autor

**Saulo BenÃ­cio**
Universidade de Fortaleza â€” UNIFOR
Curso: CiÃªncia da ComputaÃ§Ã£o
Disciplina: InteligÃªncia Artificial Computacional

---

## âš ï¸ ObservaÃ§Ãµes

âœ”ï¸ ImplementaÃ§Ã£o manual dos classificadores
âœ”ï¸ Sem uso de bibliotecas como scikit-learn ou pandas
âœ”ï¸ CÃ³digo didÃ¡tico e acadÃªmico

---